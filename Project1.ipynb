{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQAep6mya0Uv"
   },
   "source": [
    "# Fundamentals of Computer Vision\n",
    "\n",
    "This Jupyter Notebook covers **Project 1** of the course and focuses on implementing convolution, linear filtering and template matching to introduce fundamental concepts in image processing. Each section has questions that must be answered in a Document in PDF format.\n",
    "\n",
    "**Important**\n",
    "\n",
    "Both the Convolution and Linear Filter tasks (Code + Answers) must be submitted; otherwise, your work will be rejected.\n",
    "\n",
    "\n",
    "## Grading Breakdown: ##\n",
    "- Convolution: 40 points (Code: 24 pts, Answers: 16 pts).\n",
    "- Linear Filtering: 45 points (Code: 27 pts, Answers: 18 pts).\n",
    "- (OPTIONAL) Matching Template: 15 points (Code: 9 pts, Answers: 6 pts).\n",
    "\n",
    "To pass Project 1, a minimum of **50 points** is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oorq2s7wGonf"
   },
   "source": [
    "# **Convolution**\n",
    "\n",
    "In this exercise, you will implement a convolution function that applies a kernel to an input image. Follow these steps to complete the implementation of the `convolution()` function:\n",
    "\n",
    "1. Flip the kernel.\n",
    "\n",
    "2. Add padding to the input image (if padding > 0).\n",
    "\n",
    "3. Initialize an output matrix based on image and kernel dimensions.\n",
    "\n",
    "4. Perform element-wise multiplication of the flipped kernel and image region for each position, summing the results.\n",
    "\n",
    "5. Return the output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kSYWEDF0wMl9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Apply your convolution\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m custom_result \u001b[38;5;241m=\u001b[39m \u001b[43mconvolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Display the image and convolved_image\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Your code to display the images goes here!\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m, in \u001b[0;36mconvolution\u001b[1;34m(image, kernel, padding, stride)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mPerforms a convolution operation on a multi-channel image using a given kernel.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m  An array representing the output image after applying the convolution operation.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Remember to flip the kernel\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Use the np.pad() function for padding, and implement only one padding mode (e.g., constant)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Your code goes here!\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "...\n",
    "\n",
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Create a kernel\n",
    "kernel = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "def convolution(image, kernel, padding=0, stride=1):\n",
    "    \"\"\"\n",
    "    Performs a convolution operation on a multi-channel image using a given kernel.\n",
    "\n",
    "    Parameters:\n",
    "      image: A 2D array representing the input image (height, width).\n",
    "      kernel: A 2D array representing the convolution kernel (height, width).\n",
    "      padding: An integer representing the amount of padding.\n",
    "      stride: An integer representing the step size for moving the kernel.\n",
    "\n",
    "    Returns:\n",
    "      An array representing the output image after applying the convolution operation.\n",
    "    \"\"\"\n",
    "    # Remember to flip the kernel\n",
    "    # Use the np.pad() function for padding, and implement only one padding mode (e.g., constant)\n",
    "    # Your code goes here!\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Apply your convolution\n",
    "custom_result = convolution(image, kernel, padding, stride)\n",
    "\n",
    "# Display the image and convolved_image\n",
    "# Your code to display the images goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRqkeBW1Xy25"
   },
   "source": [
    "After implementing your convolution function, compare your output with results obtained from OpenCV and SciPy to verify the accuracy of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnRxU1g7W3Vs"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from scipy.signal import convolve2d\n",
    "...\n",
    "\n",
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Create a kernel\n",
    "kernel = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "### Compare outputs from your convolution implementation with OpenCV and SciPy ###\n",
    "\n",
    "# Your convolution\n",
    "custom_result = convolution(image, kernel, padding, stride)\n",
    "\n",
    "# OpenCV's convolution\n",
    "opencv_result = cv2.filter2D(image, -1, kernel, borderType=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# Scipy's convolution\n",
    "scipy_result = convolve2d( image, kernel, mode='same')\n",
    "\n",
    "# Display the custom_result, opencv_result and scipy_result\n",
    "# Your code to display the images goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLFBRomGY3Rk"
   },
   "source": [
    "**Questions that must be included in your Report**.\n",
    "\n",
    "Answer the questions briefly and directly, including the images obtained from the execution of your code to explain your conclusions. Answers must be connected to the executed code.\n",
    "\n",
    "1. How would you describe the convolution process to another student? Use your own words.\n",
    "\n",
    "2. What is the role of padding in the convolution operation, and what are the different types of padding?\n",
    "\n",
    "3. How does the stride parameter influence the convolution operation?\n",
    "\n",
    "4. How do small kernels (e.g., 3x3) and large kernels (e.g., 5x5 or 7x7) affect the outcome of the convolution operation?\n",
    "\n",
    "5. Why is OpenCV's convolution result so different from your implementation and SciPy's convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hKrGTS2AgWg"
   },
   "source": [
    "# **Linear Filtering**\n",
    "\n",
    "In this section, you will implement the following linear filters to process the provided images:\n",
    "\n",
    "- Edge Detection Filters:\n",
    "  - (A). Laplacian Filter\n",
    "  - (B). Sobel Filter\n",
    "\n",
    "- Blurring Filters:\n",
    "  - (C). Average Box Filter (also named Mean Filter)\n",
    "  - (D). Gaussian Filter  \n",
    "\n",
    "(E). You will also add noise to an image and analyse how it affects the performance of the filters.\n",
    "\n",
    "By implementing these filters, you will gain insights into their effects on image characteristics, enhancing your understanding of fundamental image processing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIfr3ZZytPti"
   },
   "source": [
    "(A). In this exercise, you will implement a **Laplacian Filter** function using your previously implemented convoluton function.\n",
    "\n",
    "Apply your Laplacian Filter function using the following Laplacian kernel:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & -4 & 1 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzXB1gk9-HlA"
   },
   "outputs": [],
   "source": [
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Create the Laplacian kernel\n",
    "laplacian_kernel = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "def laplacian_filter(image, kernel, padding, stride):\n",
    "  # Apply your previously implemented convolution function\n",
    "  # Ensure the output has the same dimensions as the input image\n",
    "  # Your code goes here!\n",
    "\n",
    "  return laplacian_output  # Output after applying the Laplacian filter\n",
    "\n",
    "# Apply the Sobel filter\n",
    "laplacian_output = laplacian_filter(image, laplacian_kernel, padding, stride)\n",
    "\n",
    "# Display the iamge and laplacian output\n",
    "# Your code goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFsZIynVB4LY"
   },
   "source": [
    "(B). Now, implement a **Sobel Filter** function by following these steps:\n",
    "1. Use your previously implemented convolution function.\n",
    "2. Calculate the gradient magnitude.\n",
    "3. Normalize the output to the range [0-255].\n",
    "4. Optionally, convert the result to uint8.\n",
    "\n",
    "Apply your Sobel Filter function using the following Sobel kernels:\n",
    "\n",
    "sobel\\_x = \\begin{bmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-2 & 0 & 2 \\\\\n",
    "-1 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\n",
    "sobel\\_y = \\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{bmatrix}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4KvA_0DEIyt"
   },
   "outputs": [],
   "source": [
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Create the Sobel kernels\n",
    "sobel_x = ...\n",
    "\n",
    "sobel_y = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "# Define the Sobel filter function\n",
    "def sobel_filter(image, kernel_x, kernel_y, padding, stride):\n",
    "  # Your code goes here!\n",
    "\n",
    "  return gradient_x, gradient_y, gradient_magnitude\n",
    "\n",
    "\n",
    "# Apply the Sobel filter\n",
    "grad_x, grad_y, grad_magnitude = sobel_filter(image, sobel_x, sobel_y, padding, stride)\n",
    "\n",
    "# Display image, grad_x, grad_y and grad_magnitude\n",
    "# Your code to display images goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0YEqj0DQ-6y"
   },
   "source": [
    "Implement the **Average Box Filter** (or Mean Filter) by following these steps:\n",
    "1. Ensure the kernel size is odd.\n",
    "2. Create the Averaging Kernel: Construct a square kernel of size\n",
    "$kernel\\_size × kernel\\_size$ where each element is set to $\\frac{1}{kernel\\_size²}$. This kernel will be used to compute the average of the neighboring pixels.\n",
    "3. Apply your previously implemented convolution function.\n",
    "\n",
    "Apply your Average Box Filter function using a square kernel of $3 \\times 3$, which is equivalent to the kernel:\n",
    "\n",
    "average_kernel =\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9} \\\\\n",
    "\\frac{1}{9} & \\frac{1}{9} & \\frac{1}{9}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwtA9bZ8WDop"
   },
   "outputs": [],
   "source": [
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Set kernel size\n",
    "kernel_size = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "def average_box_filter(image, kernel_size, padding, stride):\n",
    "  # Your code here!\n",
    "  # 1. Ensure the kernel size is odd.\n",
    "  # 2. Create the Averaging Kernel\n",
    "  # 3. Use your convolution function\n",
    "\n",
    "  # Your code goes here!\n",
    "\n",
    "  return filtered_image\n",
    "\n",
    "\n",
    "# Apply the Sobel filter\n",
    "filtered_image = average_box_filter(image, kernel_size, padding, stride)\n",
    "\n",
    "# Display the original and filtered images\n",
    "# Your code to display images goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7ylsMG4Yyy_"
   },
   "source": [
    "(C). Implement the **Gaussian Filter** by following these steps:\n",
    "\n",
    "1. Ensure the Kernel Size is Odd.\n",
    "2. Create the Gaussian Kernel using the provided **`gaussian_kernel()`** function.\n",
    "\n",
    "  This function constructs a square kernel of size $kernel\\_size \\times kernel\\_size$ and computes the kernel values using the Gaussian function defined as:\n",
    "  $kernel(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$.\n",
    "  \n",
    "  After computing the kernel values, the function normalizes the kernel to ensure that the sum of all elements equals 1. This normalization process is crucial as it allows the kernel to be used for computing the weighted average of neighboring pixels, effectively giving more importance to pixels closer to the center of the kernel.\n",
    "    \n",
    "3. Use your previously implemented convolution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlLJ1-bEY7ef"
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(kernel_size, sigma):\n",
    "    \"\"\"\n",
    "    Creates a Gaussian kernel.\n",
    "\n",
    "    Parameters:\n",
    "        kernel_size (int): Size of the kernel (must be odd).\n",
    "        sigma (float): Standard deviation for the Gaussian distribution.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Gaussian kernel.\n",
    "    \"\"\"\n",
    "    if kernel_size % 2 == 0:\n",
    "        raise ValueError(\"Kernel size must be an odd number.\")\n",
    "\n",
    "    # Create a grid of (x,y) coordinates\n",
    "    ax = np.linspace(-(kernel_size // 2), kernel_size // 2, kernel_size)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "\n",
    "    # Calculate the Gaussian function\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSlWzJJdZFG2"
   },
   "outputs": [],
   "source": [
    "# Load an image (grayscale and color)\n",
    "image = ...\n",
    "\n",
    "# Set Gaussian kernel size\n",
    "kernel_size = ...\n",
    "sigma = ...\n",
    "\n",
    "# Set needed variables\n",
    "padding = ...\n",
    "stride = ...\n",
    "\n",
    "def gaussian_filter(image, kernel_size=5, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian Filter to the given image.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.ndarray): Input image (2D array for grayscale, 3D for RGB).\n",
    "        kernel_size (int): Size of the Gaussian kernel (must be odd).\n",
    "        sigma (float): Standard deviation for the Gaussian distribution.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered image.\n",
    "    \"\"\"\n",
    "    # Create the Gaussian kernel\n",
    "    kernel = ...\n",
    "\n",
    "    # Use your convolution function\n",
    "    filtered_image = ...\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "# Apply the Gaussian filter\n",
    "filtered_image = gaussian_filter(image, kernel_size, sigma)\n",
    "\n",
    "# Display the original and filtered image\n",
    "# Your code to display images goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D95BX7B9X7DJ"
   },
   "source": [
    "(E). In the previous exercises, you applied linear filters to the original image and observed different filtered outputs. Now, you will modify the original image by adding salt-and-pepper noise. After adding the noise using the `salt_paper()` function, apply the same linear filters to the noisy image. The goal is to compare the filtered outputs of the noisy image with those of the original image to see how the noise impacts the filtering results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U65-n0FEX6RU"
   },
   "outputs": [],
   "source": [
    "def salt_pepper(image, salt_prob, pepper_prob):\n",
    "    \"\"\"\n",
    "    Add salt and pepper noise to an image.\n",
    "\n",
    "    :param image: Input image (NumPy array).\n",
    "    :param salt_prob: Probability of adding salt noise (white pixels).\n",
    "    :param pepper_prob: Probability of adding pepper noise (black pixels).\n",
    "    :return: Noisy image with salt and pepper noise added.\n",
    "    \"\"\"\n",
    "    noisy_image = np.copy(image)\n",
    "\n",
    "    # Salt noise (white pixels)\n",
    "    num_salt = np.ceil(salt_prob * image.size).astype(int)\n",
    "    coords_salt = [np.random.randint(0, i - 1, num_salt) for i in image.shape]\n",
    "    noisy_image[tuple(coords_salt)] = 255  # For salt (white)\n",
    "\n",
    "    # Pepper noise (black pixels)\n",
    "    num_pepper = np.ceil(pepper_prob * image.size).astype(int)\n",
    "    coords_pepper = [np.random.randint(0, i - 1, num_pepper) for i in image.shape]\n",
    "    noisy_image[tuple(coords_pepper)] = 0  # For pepper (black)\n",
    "\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGF1M1wvY2Wm"
   },
   "outputs": [],
   "source": [
    "# Load an image using OpenCV\n",
    "image = ...\n",
    "\n",
    "# Add salt-and-pepper noise\n",
    "salt_prob = ...\n",
    "pepper_prob = ...\n",
    "noisy_image = salt_pepper(image, salt_prob, pepper_prob)\n",
    "\n",
    "# Display the original and noisy images\n",
    "# Your code to display images goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dac-7WQMhWYX"
   },
   "source": [
    "**Questions that must be included in your Report**.\n",
    "\n",
    "Answer the questions briefly and directly, including the images obtained from the execution of your code to explain your conclusions. Answers must be connected to the executed code.\n",
    "\n",
    "6. Briefly describe the goal of each linear filter. Use your own words.\n",
    "\n",
    "7. The Sobel filter detects edges in specific directions (horizontal or vertical). What are the potential advantages and disadvantages of using a directional filter like Sobel versus a non-directional filter like Laplacian in edge detection tasks?\n",
    "\n",
    "8. After adding salt-and-pepper noise to the image, which filter (Laplacian, Sobel, Mean or Gaussian) is the most effective at reducing noise? Justify your answer with observations from the filtered outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YdiK7BU-M35"
   },
   "source": [
    "# **Template Matching** (OPTIONAL)\n",
    "\n",
    "Template Matching is a computer vision technique for identifying patterns in larger images, commonly used in image recognition and object detection. It compares a small image (template) with regions of a larger image to find similarities.\n",
    "\n",
    "A key measure of similarity in template matching is the Normalized Cross-Correlation (NCC), which normalizes the cross-correlation between the template and image regions. This normalization enhances robustness against variations in brightness and contrast.\n",
    "\n",
    "The mathematical expression for NCC between an image region and a template is defined as follows:\n",
    "\n",
    "**NCC Formula**\n",
    "\n",
    "Given:\n",
    "\n",
    "$I$: The image region of size $H \\times W$ (height $H$, width $W$)\n",
    "\n",
    "$T$: The template of size $H \\times W$\n",
    "\n",
    "$\\mu_I$: Mean of the image region $I$\n",
    "\n",
    "$\\mu_T$: Mean of the template $T$\n",
    "\n",
    "$\\sigma_I$: Standard deviation of the image region $I$\n",
    "\n",
    "$\\sigma_T$: Standard deviation of the template $T$\n",
    "\n",
    "\n",
    "The Normalized Cross-Correlation (NCC) is expressed mathematically as:\n",
    "\n",
    "# $NCC(I, T) = \\frac{\\sum_{x=0}^{W-1} \\sum_{y=0}^{H-1} (I(x, y) - \\mu_I)(T(x, y) - \\mu_T)}{\\sigma_I \\cdot \\sigma_T \\cdot H \\cdot W}\n",
    "$\n",
    "\n",
    "\n",
    "**Breakdown of the Formula**\n",
    "\n",
    "Numerator:\n",
    "* $(I(x, y) - \\mu_I)$: This term calculates the deviation of each pixel in the image region from the mean of that region.\n",
    "\n",
    "* $(T(x, y) - \\mu_T)$: This term calculates the deviation of each pixel in the template from the mean of the template.\n",
    "\n",
    "The sum of these products across all pixels in the region gives a measure of how similar the patterns in the image region and template are.\n",
    "\n",
    "Denominator:\n",
    "\n",
    "* $\\sigma_I$: The standard deviation of the image region, which accounts for the variability of pixel values in that region.\n",
    "* $\\sigma_T$: The standard deviation of the template, which does the same for the template.\n",
    "* $H \\cdot W$: The total number of pixels in the image region (or template), normalizing the result to make it independent of the size of the area being compared.\n",
    "\n",
    "\n",
    "Result Interpretation\n",
    "\n",
    "The resulting NCC value will be between $-1$ and $1$:\n",
    "* $1$: Perfect correlation (the image region matches the template exactly).\n",
    "* $0$: No correlation.\n",
    "* $-1$: Perfect negative correlation (the image region is the opposite of the template).\n",
    "\n",
    "\n",
    "This formula captures both the shape and the intensity distributions of the image region and the template, making it robust against changes in brightness and contrast.\n",
    "\n",
    "---\n",
    "\n",
    "The provided code performs template matching using NCC. You will:\n",
    "\n",
    "1. Implement the NCC computation inside `normalized_cross_correlation()` and return the corresponding output.\n",
    "2. Filter the resulting NCC values based on a correlation threshold.\n",
    "3. Draw bounding boxes around the areas in the image where high correlation values are found (matches).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEjTSmNdxaAs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfVk5dtjtNcE"
   },
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image, matches, template_shape):\n",
    "    # Copy the image to draw on\n",
    "    output_image = np.copy(image)\n",
    "    tmpl_height, tmpl_width = template_shape\n",
    "\n",
    "    for _, (x, y) in matches:\n",
    "        # Draw rectangle (bounding box)\n",
    "        output_image[x:x + tmpl_height, y:y + tmpl_width] = 100 # Change this gray level as needed.\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34S1LHEkxEtV"
   },
   "outputs": [],
   "source": [
    "def load_templates(files_path):\n",
    "  templates = []\n",
    "\n",
    "  for filename in (files_path):\n",
    "    template = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    templates.append((template, (template.shape[0], template.shape[1])))\n",
    "\n",
    "  return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CReY6mzw4QH"
   },
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(image, template):\n",
    "    # Get dimensions of image and template\n",
    "    img_height, img_width = image.shape\n",
    "    tmpl_height, tmpl_width = template.shape\n",
    "\n",
    "    # Compute mean and standard deviation of the template\n",
    "    mu_T = template.mean()  # Mean of the template\n",
    "    sigma_T = template.std()  # Standard deviation of the template\n",
    "\n",
    "    # Prepare an array to hold NCC results\n",
    "    ncc_result = []\n",
    "\n",
    "    # Iterate through the image\n",
    "    for i in range(img_height - tmpl_height + 1):\n",
    "        for j in range(img_width - tmpl_width + 1):\n",
    "\n",
    "\n",
    "            # Your code goes here!\n",
    "\n",
    "\n",
    "            # Append the NCC value and coordinates to the results\n",
    "            ncc_result.append((ncc_value, (i, j)))\n",
    "\n",
    "    return ncc_result\n",
    "\n",
    "# \"\"\"\n",
    "#   Example of Output: ncc_result\n",
    "#   Here's an example of what the output might look like:\n",
    "#   [\n",
    "#       (0.85, (50, 100)),  # High correlation at (50, 100)\n",
    "#       (0.92, (150, 200)), # Very high correlation at (150, 200)\n",
    "#       (0.78, (300, 400)), # Moderate correlation at (300, 400)\n",
    "#       # Additional matches...\n",
    "#   ]\n",
    "#   \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8jFPBQr2U6x"
   },
   "outputs": [],
   "source": [
    "def filter_results(ncc_result, threshold):\n",
    "  # Filter the results for high correlation values\n",
    "  high_correlation_results = []\n",
    "  for value, (x, y) in ncc_result:\n",
    "    if value > threshold:\n",
    "      high_correlation_results.append((value, (x, y)))\n",
    "\n",
    "  return high_correlation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhXORrO_yShw"
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "image = ...\n",
    "\n",
    "# Load templates\n",
    "files_path = [\"template/template_Circle.png\",\n",
    "              \"template/template_E.png\",\n",
    "              \"template/template_H.png\",\n",
    "              \"template/template_L.png\",\n",
    "              \"template/template_O.png\",\n",
    "              \"template/template_Square.png\",\n",
    "              \"template/template_Triangle.png\"]\n",
    "\n",
    "templates = load_templates(files_path)\n",
    "\n",
    "# Store matches\n",
    "all_matches = []\n",
    "\n",
    "# Set matching threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Perform template matching for each template\n",
    "for template, shape in templates:\n",
    "  matches = normalized_cross_correlation(image, template)\n",
    "  matches = filter_results(matches, threshold)\n",
    "  all_matches.extend(matches)\n",
    "\n",
    "# # Draw bounding boxes around matches\n",
    "result_image = draw_bounding_boxes(image, all_matches, shape)\n",
    "\n",
    "# Display result image\n",
    "# Your code goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVBs_-okmefn"
   },
   "source": [
    "**Questions that must be included in your Report**.\n",
    "\n",
    "Answer the questions briefly and directly, including the images obtained from the execution of your code to explain your conclusions. Answers must be connected to the executed code.\n",
    "\n",
    "9. What is the goal of template matching in computer vision?\n",
    "Briefly describe the purpose and typical applications of template matching.\n",
    "\n",
    "10. Explain the role of Normalized Cross-Correlation (NCC) in template matching. Why is normalization important in comparing image regions and templates?\n",
    "\n",
    "11. In your own words, explain the meaning of an NCC value of 1, 0, and -1.\n",
    "What does each of these values indicate about the similarity between the image region and the template? Relate your answers to your output results."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
